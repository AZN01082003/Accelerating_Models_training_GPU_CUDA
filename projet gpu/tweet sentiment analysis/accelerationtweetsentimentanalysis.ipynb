{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "twitter sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T15:04:29.071125Z",
     "iopub.status.busy": "2025-01-05T15:04:29.070854Z",
     "iopub.status.idle": "2025-01-05T15:04:38.285623Z",
     "shell.execute_reply": "2025-01-05T15:04:38.284755Z",
     "shell.execute_reply.started": "2025-01-05T15:04:29.071103Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-05 15:04:36,959] [INFO] Created vocabulary\n",
      "[2025-01-05 15:04:36,962] [INFO] Finished initializing nlp object\n",
      "[2025-01-05 15:04:38,186] [INFO] Created vocabulary\n",
      "[2025-01-05 15:04:38,189] [INFO] Finished initializing nlp object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel training complete in 3.32 seconds!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from spacy.training import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Vérification du GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Charger les données\n",
    "df_train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\n",
    "\n",
    "# Prétraitement\n",
    "df_train['Num_words_text'] = df_train['text'].apply(lambda x: len(str(x).split()))\n",
    "df_train = df_train[df_train['Num_words_text'] >= 3]\n",
    "\n",
    "# Fonction de préparation des données\n",
    "def get_training_data(sentiment):\n",
    "    train_data = []\n",
    "    for _, row in df_train.iterrows():\n",
    "        if row.sentiment == sentiment:\n",
    "            selected_text = row.selected_text\n",
    "            text = row.text\n",
    "            start = text.find(selected_text)\n",
    "            end = start + len(selected_text)\n",
    "            train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n",
    "    return train_data\n",
    "\n",
    "# Fonction d'entraînement sur GPU avec mesure du temps d'exécution\n",
    "def train(train_data, output_dir, n_iter=20, model=None):\n",
    "    start_time = time.time()  # Commencer à mesurer le temps d'exécution\n",
    "    nlp = spacy.blank(\"en\") if model is None else spacy.load(model)\n",
    "    \n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.add_pipe(\"ner\")\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "    # Ajout des labels NER\n",
    "    for _, annotations in train_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # Désactiver les autres pipes pour accélérer l'entraînement\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "    with nlp.disable_pipes(*other_pipes):\n",
    "        optimizer = nlp.begin_training()\n",
    "        nlp.to(device)  # Déplacement du modèle vers le GPU\n",
    "\n",
    "        # Entraînement avec mise à jour des poids\n",
    "        for _ in tqdm(range(n_iter)):\n",
    "            random.shuffle(train_data)\n",
    "            batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))  # Taille de mini-lots optimisée\n",
    "            losses = {}\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                examples = [Example.from_dict(nlp.make_doc(text), annotation) for text, annotation in batch]\n",
    "                nlp.update(examples, drop=0.3, losses=losses)  # Taux de dropout ajusté\n",
    "            print(f\"Losses at iteration {_}: {losses}\")\n",
    "\n",
    "    # Sauvegarde du modèle\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    nlp.to_disk(output_dir)\n",
    "    print(f\"Model saved to {output_dir}\")\n",
    "\n",
    "    # Mesure du temps d'entraînement\n",
    "    print(f\"Training time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Entraînement parallèle avec mesure du temps total\n",
    "def parallel_training():\n",
    "    start_time = time.time()  # Commencer à mesurer le temps total de l'entraînement\n",
    "    sentiments = ['positive', 'negative']\n",
    "    \n",
    "    pool = Pool(processes=len(sentiments))  # Parallélisme pour chaque sentiment\n",
    "    results = []\n",
    "    \n",
    "    for sentiment in sentiments:\n",
    "        train_data = get_training_data(sentiment)\n",
    "        output_dir = f'model_{sentiment}'\n",
    "        # Appliquer la fonction d'entraînement en parallèle\n",
    "        results.append(pool.apply_async(train, (train_data, output_dir, 20, None)))\n",
    "    \n",
    "    pool.close()  # Fermeture du pool de processus\n",
    "    pool.join()  # Attendre la fin de l'entraînement parallèle\n",
    "\n",
    "    # Temps total d'exécution de l'entraînement parallèle\n",
    "    print(f\"Parallel training complete in {time.time() - start_time:.2f} seconds!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parallel_training()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 1099992,
     "sourceId": 16295,
     "sourceType": "competition"
    },
    {
     "sourceId": 6989832,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
