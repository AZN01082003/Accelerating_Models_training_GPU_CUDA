



# Accélération des Modèles d'Apprentissage Profond sur GPU  

Ce projet explore l'optimisation des modèles de machine learning en utilisant des technologies GPU avancées telles que CUDA, la parallélisation multi-GPU et des bibliothèques optimisées comme TensorFlow et PyTorch.  

## Contenu du projet  
Nous avons sélectionné et analysé six projets issus de Kaggle pour démontrer comment l'accélération matérielle peut améliorer la vitesse d'exécution et la performance globale des modèles :  

1. **Twitter Sentiment Analysis** – Extraction, analyse exploratoire des données (EDA) et modélisation.  
2. **Recurrent Neural Networks (RNN)** – Introduction aux architectures LSTM et GRU.  
3. **Time Series Modelling** – Prédiction des actions Google avec Python LSTM.  
4. **Diabetes Prediction** – Optimisation et tuning d'un réseau de neurones artificiel (ANN).  
5. **Guava Disease Classification** – Classification des maladies des goyaves avec un CNN.  
6. **Quantum-Enhanced Convolutional Neural Networks** – Expérimentation de CNN optimisés via des techniques quantiques.  

## Objectifs  
- Étudier l'impact de l'accélération GPU sur différents modèles de deep learning.  
- Comparer l'entraînement sur CPU vs GPU.  
- Optimiser l'utilisation des ressources matérielles pour améliorer les performances.  

## Technologies utilisées  
- **Frameworks** : TensorFlow, PyTorch  
- **Optimisation GPU** : CUDA, multi-GPU  
- **Types de modèles** : CNN, LSTM, RNN, ANN  

